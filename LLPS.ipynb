{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMIRMOHAMMAD-OSS/classi/blob/main/LLPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyzTHwf8dRBy",
        "outputId": "19759785-a127-4700-d15f-330b55a5ce1d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'classi'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 33 (delta 12), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (33/33), 14.07 MiB | 9.17 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Collecting slack-sdk\n",
            "  Downloading slack_sdk-3.27.1-py2.py3-none-any.whl (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: slack-sdk\n",
            "Successfully installed slack-sdk-3.27.1\n"
          ]
        }
      ],
      "source": [
        "#@title Importing libraries\n",
        "!git clone https://github.com/AMIRMOHAMMAD-OSS/classi\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "!pip install slack-sdk\n",
        "from tqdm.contrib.slack import tqdm, trange\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "from ast import literal_eval\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "from tokenizers import Tokenizer, decoders, models, normalizers, pre_tokenizers, trainers\n",
        "from transformers import CanineTokenizer, CanineModel\n",
        "tokenizer = Tokenizer.from_file(\"classi/Trained_BPE2.json\")\n",
        "tokenizer.model_max_length = 256\n",
        "tokenizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler as Sc\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split as TTS\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split as TTS\n",
        "\n",
        "\n",
        "def edit(x):\n",
        "    for i in x:\n",
        "      if i in \"BJOUX\\Z_n\\n\":\n",
        "        x = x.replace(i,\"\")\n",
        "      else:\n",
        "        pass\n",
        "    return x\n",
        "\n",
        "def encode(x):\n",
        "  l = []\n",
        "  chars = tokenizer.get_vocab()\n",
        "  for i in x:\n",
        "    l.append(chars[i])\n",
        "  return l\n",
        "\n",
        "with open(\"classi/training.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "  k = \"#\".join([i for i in edit(text).split(\"<|edoftext|>\")])\n",
        "chars = tokenizer.get_vocab()\n",
        "vocab_size = len(tokenizer.get_vocab())\n",
        "\n",
        "with open(\"classi/validation.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "  l = \"#\".join([i for i in edit(text).split(\"<|edoftext|>\")])\n",
        "\n",
        "def Padding(x,PAD = 0,max_len = 512):\n",
        "  l = []\n",
        "  max_len = max(512,len(max(x,key = lambda x: len(x))))\n",
        "  for i in x:\n",
        "    a = i\n",
        "    if len(a) < max_len:\n",
        "      a = a + [PAD for i in range(max_len-len(a))]\n",
        "    l.append(a)\n",
        "  return np.array(l).reshape(len(x),max_len)\n",
        "with open(\"classi/negative_dataset.txt\") as x:\n",
        "  c = x.read()\n",
        "Filtered_train  = [i for i in k.split(\"#\") if len(i)<= 512][1:]\n",
        "Filtered_val = [i for i in l.split(\"#\") if len(i)<= 512][1:]\n",
        "Filtered_neg = [i for i in c.split(\"\\n\") if len(i)<= 512]\n",
        "pos = Filtered_train + Filtered_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "Yc9VXFLYN-x6"
      },
      "outputs": [],
      "source": [
        "#@title Loading models and requierments\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def setup_logging(config):\n",
        "    work_dir = config.system.work_dir\n",
        "    os.makedirs(work_dir, exist_ok=True)\n",
        "    with open(os.path.join(work_dir, 'args.txt'), 'w') as f:\n",
        "        f.write(' '.join(sys.argv))\n",
        "    with open(os.path.join(work_dir, 'config.json'), 'w') as f:\n",
        "        f.write(json.dumps(config.to_dict(), indent=4))\n",
        "\n",
        "class CfgNode:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self._str_helper(0)\n",
        "\n",
        "    def _str_helper(self, indent):\n",
        "        parts = []\n",
        "        for k, v in self.__dict__.items():\n",
        "            if isinstance(v, CfgNode):\n",
        "                parts.append(\"%s:\\n\" % k)\n",
        "                parts.append(v._str_helper(indent + 1))\n",
        "            else:\n",
        "                parts.append(\"%s: %s\\n\" % (k, v))\n",
        "        parts = [' ' * (indent * 4) + p for p in parts]\n",
        "        return \"\".join(parts)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return { k: v.to_dict() if isinstance(v, CfgNode) else v for k, v in self.__dict__.items() }\n",
        "\n",
        "    def merge_from_dict(self, d):\n",
        "        self.__dict__.update(d)\n",
        "\n",
        "    def merge_from_args(self, args):\n",
        "\n",
        "        for arg in args:\n",
        "            keyval = arg.split('=')\n",
        "            assert len(keyval) == 2, \"expecting each override arg to be of form --arg=value, got %s\" % arg\n",
        "            key, val = keyval\n",
        "            try:\n",
        "                val = literal_eval(val)\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "            assert key[:2] == '--'\n",
        "            key = key[2:]\n",
        "            keys = key.split('.')\n",
        "            obj = self\n",
        "            for k in keys[:-1]:\n",
        "                obj = getattr(obj, k)\n",
        "            leaf_key = keys[-1]\n",
        "            assert hasattr(obj, leaf_key), f\"{key} is not an attribute that exists in the config\"\n",
        "            print(\"command line overwriting config attribute %s with %s\" % (key, val))\n",
        "            setattr(obj, leaf_key, val)\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class SiLU(nn.Module):\n",
        "   def forward(self, x):\n",
        "        return x*F.sigmoid(x)\n",
        "\n",
        "class NY(nn.Module):\n",
        "  def forward(self,x):\n",
        "    return 3*torch.tanh(0.3*x)\n",
        "\n",
        "class NewGELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_dropout(att)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = nn.ModuleDict(dict(\n",
        "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            act     = NewGELU(),\n",
        "            dropout = nn.Dropout(config.resid_pdrop),\n",
        "        ))\n",
        "        m = self.mlp\n",
        "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x))))\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlpf(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class ClassifierII(nn.Module):\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.model_type = 'gpt'\n",
        "        C.n_layer = None\n",
        "        C.n_head = None\n",
        "        C.n_embd =  None\n",
        "        C.vocab_size = len(chars)\n",
        "        C.max_length = 512\n",
        "        C.embd_pdrop = 0.1\n",
        "        C.resid_pdrop = 0.1\n",
        "        C.attn_pdrop = 0.1\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.max_length = config.block_size\n",
        "        self.soft = nn.Softmax(1)\n",
        "        self.config = self.get_default_config()\n",
        "        self.device = \"cuda\"\n",
        "        self.model_states = {'h':{'n_layer': 48, 'n_head': 25, 'n_embd': 1600},\n",
        "                                    'g':{'n_layer': 12, '': 12, 'n_embd': 768},\n",
        "                'f':   {'n_layer': 24, 'n_head': 16, 'n_embd': 1024},\n",
        "                'e':   {'n_layer': 36, 'n_head': 20, 'n_embd': 1280},\n",
        "                'd':{'n_layer': 8, 'n_head': 16, 'n_embd': 512},\n",
        "                'c':{'n_layer': 6, 'n_head': 6, 'n_embd': 192},\n",
        "                'b':{'n_layer': 4, 'n_head': 4, 'n_embd': 128},\n",
        "                'a':{'n_layer': 3, 'n_head': 3, 'n_embd': 48}}\n",
        "\n",
        "        type_ = config.model_type is not None\n",
        "        #assert type_ in \"abcdefgh\"\n",
        "        p = all([config.n_layer is not None, config.n_head is not None, config.n_embd is not None])\n",
        "        #assert type_ == True and p == True\n",
        "        if type_:\n",
        "            config.merge_from_dict(self.model_states[config.model_type])\n",
        "        self.closs = nn.BCELoss()\n",
        "        self.ny = NY()\n",
        "        self.l = nn.Linear(512,1,64)\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.max_length, config.n_embd),\n",
        "            drop = nn.Dropout(config.embd_pdrop),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),))\n",
        "        self.classifier_head = nn.Sequential(#nn.Tanh(),\n",
        "                                             nn.Linear(config.n_embd, 2)\n",
        "                                             )\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
        "        print(\"[ Number of trainable parameters: %.2fM ]\" % (n_params/1e6,))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "            torch.nn.init.ones_(module.weight)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        config = cls.get_default_config()\n",
        "        config.model_type = model_type\n",
        "        config.vocab_size = 25\n",
        "        config.max_length = 512\n",
        "        model = ClassifierII(config)\n",
        "        sd = model.state_dict()\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "        keys = [k for k in sd_hf if not k.endswith('attn.masked_bias')]\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        assert len(keys) == len(sd)\n",
        "        for k in keys:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        decay = set()\n",
        "        no_decay = set()\n",
        "        whitelist_weight_modules = (torch.nn.Linear, )\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        for mn, m in self.named_modules():\n",
        "            for pn, p in m.named_parameters():\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn\n",
        "                if pn.endswith('bias'):\n",
        "                    no_decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    no_decay.add(fpn)\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        inter_params = decay & no_decay\n",
        "        union_params = decay | no_decay\n",
        "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                    % (str(param_dict.keys() - union_params), )\n",
        "        optim_groups = [\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},]\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
        "        return optimizer\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict_proba(self,idx,j =\"None\"):\n",
        "      sigmoid = nn.Sigmoid()\n",
        "      soft = nn.Softmax(dim=1)\n",
        "      ny = NY()\n",
        "      si = SiLU()\n",
        "      self.eval()\n",
        "      x,_ = self.forward(idx)\n",
        "      if j == \"None\":\n",
        "        return x[:,0:1]\n",
        "      elif j == \"soft\":\n",
        "        return self.soft(x)[:,0:1]\n",
        "      else:\n",
        "        return sigmoid(x)[:,0:1]\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict(self,idx):\n",
        "      g = torch.zeros((idx.shape[0],1))\n",
        "      e = -1\n",
        "      for i in self.predict_proba(idx):\n",
        "        e+=1\n",
        "        if i[0].item()>=0.5:\n",
        "          g[e] = 1\n",
        "      return g\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.classifier_head(x).view(b,2,t).to(device)\n",
        "        logits = self.l(logits)\n",
        "        logits = F.sigmoid(self.ny(logits).view(b,2).mean(1).view(b,1))\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.binary_cross_entropy(logits,targets)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.device = 'cuda'\n",
        "        C.num_workers = 4\n",
        "        C.max_iters = None\n",
        "        C.batch_size = 128\n",
        "        C.max_length = 512\n",
        "        C.learning_rate = 8e-4\n",
        "        C.betas = (0.9, 0.95)\n",
        "        C.weight_decay = 0.1\n",
        "        C.grad_norm_clip = 1.0\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config, model, train_dataset,val_dataset):\n",
        "        self.config = config\n",
        "        self.model = model\n",
        "        self.optimizer = None\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "        self.callbacks = defaultdict(list)\n",
        "        self.device ='cuda'\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.iter_num = 0\n",
        "        self.iter_time = 0.0\n",
        "        self.iter_dt = 0.0\n",
        "\n",
        "    def add_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent].append(callback)\n",
        "\n",
        "    def set_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent] = [callback]\n",
        "\n",
        "    def trigger_callbacks(self, onevent: str):\n",
        "        for callback in self.callbacks.get(onevent, []):\n",
        "            callback(self)\n",
        "\n",
        "    def run(self):\n",
        "        model, config = self.model, self.config\n",
        "        self.optimizer = model.configure_optimizers(config)\n",
        "        batch_size = self.config.batch_size\n",
        "        def get_batch(mode):\n",
        "            batch_size = 64\n",
        "            if mode == \"train\":\n",
        "              data = train_dataset\n",
        "              pos_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]),513))\n",
        "              neg_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]),513))\n",
        "              N = np.random.randint(batch_size)\n",
        "              ix_pos = np.random.randint(pos_train.shape[0]-N)\n",
        "              ix_neg = np.random.randint(neg_train.shape[0]-batch_size-N)\n",
        "              pos_data = pos_train[ix_pos:ix_pos+N,:]\n",
        "              neg_data = neg_train[ix_neg:ix_neg+batch_size-N,:]\n",
        "              data = torch.concat((pos_data,neg_data))\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,1), device=\"cuda\")\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o] = 1\n",
        "                #else:\n",
        "                  #targets[o][1] = 1\n",
        "            else:\n",
        "              data = val_dataset\n",
        "              ix = np.random.randint(data.shape[0]-batch_size)\n",
        "              data = data[ix:ix+batch_size,:]\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,1), device=\"cuda\")\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o] = 1\n",
        "                #else:\n",
        "                 # targets[o][1] = 1\n",
        "            targets = targets.view(batch_size,1).to(\"cuda\")\n",
        "            seq = seq.view(batch_size,512).to(\"cuda\")\n",
        "            return seq, targets\n",
        "\n",
        "        @torch.no_grad\n",
        "        def cross_val():\n",
        "          model.eval()\n",
        "          out = []\n",
        "          for i in [\"train\",\"val\"]:\n",
        "            losses = torch.zeros(200+1)\n",
        "            for k in range(200):\n",
        "              X,Y = get_batch(i)\n",
        "              logits,loss = model(X,Y)\n",
        "              losses[k]=loss.item()\n",
        "              out1 = losses.mean()\n",
        "            out.append(out1)\n",
        "          model.train()\n",
        "          return out\n",
        "        losses = cross_val()\n",
        "        LOSS = [losses]\n",
        "        print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        model.train()\n",
        "        for epoch in range(20):\n",
        "          print(\"[epoch {o}] \\n\".format(o = epoch))\n",
        "          iters = 200\n",
        "          for i in range(iters):\n",
        "            if i == 0:\n",
        "              Y = \"| =\"\n",
        "            elif i == iters -1 :\n",
        "              Y = \"=> 100% |\"\n",
        "            else:\n",
        "              if i%(int(iters/50)) == 0 :\n",
        "                Y = \"=\"\n",
        "              else:\n",
        "                Y = \"\"\n",
        "            print(\"{y}\".format(y = Y),end=\"\")\n",
        "            x, y = get_batch(\"train\")\n",
        "            logits, self.loss = model(x, y)\n",
        "            model.zero_grad(set_to_none=True)\n",
        "            self.loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
        "            self.optimizer.step()\n",
        "          losses = cross_val()\n",
        "          LOSS.append(losses)\n",
        "          print(LOSS)\n",
        "          print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        PATH = \"model {h}\".format(h = model_config.model_type)\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def setup_logging(config):\n",
        "    work_dir = config.system.work_dir\n",
        "    os.makedirs(work_dir, exist_ok=True)\n",
        "    with open(os.path.join(work_dir, 'args.txt'), 'w') as f:\n",
        "        f.write(' '.join(sys.argv))\n",
        "    with open(os.path.join(work_dir, 'config.json'), 'w') as f:\n",
        "        f.write(json.dumps(config.to_dict(), indent=4))\n",
        "\n",
        "class CfgNode:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self._str_helper(0)\n",
        "\n",
        "    def _str_helper(self, indent):\n",
        "        parts = []\n",
        "        for k, v in self.__dict__.items():\n",
        "            if isinstance(v, CfgNode):\n",
        "                parts.append(\"%s:\\n\" % k)\n",
        "                parts.append(v._str_helper(indent + 1))\n",
        "            else:\n",
        "                parts.append(\"%s: %s\\n\" % (k, v))\n",
        "        parts = [' ' * (indent * 4) + p for p in parts]\n",
        "        return \"\".join(parts)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return { k: v.to_dict() if isinstance(v, CfgNode) else v for k, v in self.__dict__.items() }\n",
        "\n",
        "    def merge_from_dict(self, d):\n",
        "        self.__dict__.update(d)\n",
        "\n",
        "    def merge_from_args(self, args):\n",
        "\n",
        "        for arg in args:\n",
        "            keyval = arg.split('=')\n",
        "            assert len(keyval) == 2, \"expecting each override arg to be of form --arg=value, got %s\" % arg\n",
        "            key, val = keyval\n",
        "            try:\n",
        "                val = literal_eval(val)\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "            assert key[:2] == '--'\n",
        "            key = key[2:]\n",
        "            keys = key.split('.')\n",
        "            obj = self\n",
        "            for k in keys[:-1]:\n",
        "                obj = getattr(obj, k)\n",
        "            leaf_key = keys[-1]\n",
        "            assert hasattr(obj, leaf_key), f\"{key} is not an attribute that exists in the config\"\n",
        "            print(\"command line overwriting config attribute %s with %s\" % (key, val))\n",
        "            setattr(obj, leaf_key, val)\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class SiLU(nn.Module):\n",
        "   def forward(self, x):\n",
        "        return x*F.sigmoid(x)\n",
        "\n",
        "class NY(nn.Module):\n",
        "  def forward(self,x):\n",
        "    return 3*torch.tanh(0.3*x)\n",
        "\n",
        "class NewGELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_dropout(att)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = nn.ModuleDict(dict(\n",
        "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            act     = NewGELU(),\n",
        "            dropout = nn.Dropout(config.resid_pdrop),\n",
        "        ))\n",
        "        m = self.mlp\n",
        "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x))))\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlpf(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class ClassifierI(nn.Module):\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.model_type = 'gpt'\n",
        "        C.n_layer = None\n",
        "        C.n_head = None\n",
        "        C.n_embd =  None\n",
        "        C.vocab_size = len(chars)\n",
        "        C.max_length = 512\n",
        "        C.embd_pdrop = 0.1\n",
        "        C.resid_pdrop = 0.1\n",
        "        C.attn_pdrop = 0.1\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.max_length = config.block_size\n",
        "        self.soft = nn.Softmax(1)\n",
        "        self.config = self.get_default_config()\n",
        "        self.device = \"cpu\"\n",
        "        self.model_states = {'h':{'n_layer': 48, 'n_head': 25, 'n_embd': 1600},\n",
        "                                    'g':{'n_layer': 12, '': 12, 'n_embd': 768},\n",
        "                'f':   {'n_layer': 24, 'n_head': 16, 'n_embd': 1024},\n",
        "                'e':   {'n_layer': 36, 'n_head': 20, 'n_embd': 1280},\n",
        "                'd':{'n_layer': 8, 'n_head': 16, 'n_embd': 512},\n",
        "                'c':{'n_layer': 6, 'n_head': 6, 'n_embd': 192},\n",
        "                'b':{'n_layer': 4, 'n_head': 4, 'n_embd': 128},\n",
        "                'a':{'n_layer': 3, 'n_head': 3, 'n_embd': 48}}\n",
        "\n",
        "        type_ = config.model_type is not None\n",
        "        #assert type_ in \"abcdefgh\"\n",
        "        p = all([config.n_layer is not None, config.n_head is not None, config.n_embd is not None])\n",
        "        #assert type_ == True and p == True\n",
        "        if type_:\n",
        "            config.merge_from_dict(self.model_states[config.model_type])\n",
        "        self.closs = nn.BCELoss()\n",
        "        self.ny = NY()\n",
        "        #self.l = nn.Linear(512,1,64)\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.max_length, config.n_embd),\n",
        "            drop = nn.Dropout(config.embd_pdrop),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),))\n",
        "        self.classifier_head = nn.Sequential(#nn.Tanh(),\n",
        "                                             nn.Linear(config.n_embd, 2)\n",
        "                                             )\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
        "        #print(\"[ Number of trainable parameters: %.2fM ]\" % (n_params/1e6,))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "            torch.nn.init.ones_(module.weight)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        config = cls.get_default_config()\n",
        "        config.model_type = model_type\n",
        "        config.vocab_size = 25\n",
        "        config.max_length = 512\n",
        "        model = ClassifierI(config)\n",
        "        sd = model.state_dict()\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "        keys = [k for k in sd_hf if not k.endswith('attn.masked_bias')]\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        assert len(keys) == len(sd)\n",
        "        for k in keys:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        decay = set()\n",
        "        no_decay = set()\n",
        "        whitelist_weight_modules = (torch.nn.Linear, )\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        for mn, m in self.named_modules():\n",
        "            for pn, p in m.named_parameters():\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn\n",
        "                if pn.endswith('bias'):\n",
        "                    no_decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    no_decay.add(fpn)\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        inter_params = decay & no_decay\n",
        "        union_params = decay | no_decay\n",
        "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                    % (str(param_dict.keys() - union_params), )\n",
        "        optim_groups = [\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},]\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
        "        return optimizer\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict_proba(self,idx,j =\"None\"):\n",
        "      sigmoid = nn.Sigmoid()\n",
        "      soft = nn.Softmax(dim=1)\n",
        "      ny = NY()\n",
        "      si = SiLU()\n",
        "      self.eval()\n",
        "      x,_ = self.forward(idx)\n",
        "      if j == \"None\":\n",
        "        return x[:,0:1]\n",
        "      elif j == \"soft\":\n",
        "        return self.soft(x)[:,0:1]\n",
        "      else:\n",
        "        return sigmoid(x)[:,0:1]\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict(self,idx):\n",
        "      g = torch.zeros((idx.shape[0],1))\n",
        "      e = -1\n",
        "      for i in self.predict_proba(idx):\n",
        "        e+=1\n",
        "        if i[0].item()>=0.5:\n",
        "          g[e] = 1\n",
        "      return g\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.ny(self.classifier_head(x)).mean(1).to(device)\n",
        "        #logits = self.l(logits)\n",
        "        # = F.sigmoid(logits.view(b,2).mean(1).view(b,1))\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits,targets,ignore_index = -1)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.device = 'cuda'\n",
        "        C.num_workers = 4\n",
        "        C.max_iters = None\n",
        "        C.batch_size = 64\n",
        "        C.max_length = 512\n",
        "        C.learning_rate = 8e-4\n",
        "        C.betas = (0.9, 0.95)\n",
        "        C.weight_decay = 0.1\n",
        "        C.grad_norm_clip = 1.0\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config, model, train_dataset,val_dataset):\n",
        "        self.config = config\n",
        "        self.model = model\n",
        "        self.optimizer = None\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "        self.callbacks = defaultdict(list)\n",
        "        self.device ='cuda'\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.iter_num = 0\n",
        "        self.iter_time = 0.0\n",
        "        self.iter_dt = 0.0\n",
        "\n",
        "    def add_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent].append(callback)\n",
        "\n",
        "    def set_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent] = [callback]\n",
        "\n",
        "    def trigger_callbacks(self, onevent: str):\n",
        "        for callback in self.callbacks.get(onevent, []):\n",
        "            callback(self)\n",
        "\n",
        "    def run(self):\n",
        "        model, config = self.model, self.config\n",
        "        self.optimizer = model.configure_optimizers(config)\n",
        "        batch_size = self.config.batch_size\n",
        "        def get_batch(mode):\n",
        "            batch_size = 64\n",
        "            if mode == \"train\":\n",
        "              data = train_dataset\n",
        "              pos_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]),513))\n",
        "              neg_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]),513))\n",
        "              N = np.random.randint(batch_size)\n",
        "              ix_pos = np.random.randint(pos_train.shape[0]-N)\n",
        "              ix_neg = np.random.randint(neg_train.shape[0]-batch_size-N)\n",
        "              pos_data = pos_train[ix_pos:ix_pos+N,:]\n",
        "              neg_data = neg_train[ix_neg:ix_neg+batch_size-N,:]\n",
        "              data = torch.concat((pos_data,neg_data))\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,2), device=self.device)\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o][0] = 1\n",
        "                else:\n",
        "                  targets[o][1] = 1\n",
        "            else:\n",
        "              data = val_dataset\n",
        "              ix = np.random.randint(data.shape[0]-batch_size)\n",
        "              data = data[ix:ix+batch_size,:]\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,2), device=self.device)\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o][0] = 1\n",
        "                else:\n",
        "                  targets[o][1] = 1\n",
        "            targets = targets.view(batch_size,2).to(self.device)\n",
        "            seq = seq.view(batch_size,512).to(self.device)\n",
        "            return seq, targets\n",
        "\n",
        "        @torch.no_grad\n",
        "        def cross_val():\n",
        "          model.eval()\n",
        "          out = []\n",
        "          for i in [\"train\",\"val\"]:\n",
        "            losses = torch.zeros(200+1)\n",
        "            for k in range(200):\n",
        "              X,Y = get_batch(i)\n",
        "              logits,loss = model(X,Y)\n",
        "              losses[k]=loss.item()\n",
        "              out1 = losses.mean()\n",
        "            out.append(out1)\n",
        "          model.train()\n",
        "          return out\n",
        "        losses = cross_val()\n",
        "        LOSS = [losses]\n",
        "        print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        model.train()\n",
        "        for epoch in range(20):\n",
        "          print(\"[epoch {o}] \\n\".format(o = epoch))\n",
        "          iters = 200\n",
        "          for i in range(iters):\n",
        "            if i == 0:\n",
        "              Y = \"| =\"\n",
        "            elif i == iters -1 :\n",
        "              Y = \"=> 100% |\"\n",
        "            else:\n",
        "              if i%(int(iters/50)) == 0 :\n",
        "                Y = \"=\"\n",
        "              else:\n",
        "                Y = \"\"\n",
        "            print(\"{y}\".format(y = Y),end=\"\")\n",
        "            x, y = get_batch(\"train\")\n",
        "            logits, self.loss = model(x, y)\n",
        "            model.zero_grad(set_to_none=True)\n",
        "            self.loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
        "            self.optimizer.step()\n",
        "          losses = cross_val()\n",
        "          LOSS.append(losses)\n",
        "          print(LOSS)\n",
        "          print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        PATH = \"model {h}\".format(h = model_config.model_type)\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "class Transformer():\n",
        "  def __init__(self,mode):\n",
        "    self.mode = mode\n",
        "    self.device = torch.device(\"cuda\")\n",
        "    self.vocab_dict = tokenizer.get_vocab()\n",
        "\n",
        "  def classifier(self):\n",
        "    device = self.device\n",
        "    model_config = ClassifierI.get_default_config()\n",
        "    model_config = ClassifierI.get_default_config()\n",
        "    model_config.vocab_size = 25\n",
        "    model_config.block_size = 512\n",
        "    if self.mode == \"b\":\n",
        "      model_config.model_type = 'b'\n",
        "      model2 = ClassifierI(model_config)\n",
        "      model2.load_state_dict(torch.load(\"classi/model_b\",map_location=self.device))\n",
        "    else:\n",
        "      model_config.model_type = 'c'\n",
        "      model2 = ClassifierI(model_config)\n",
        "      model2.load_state_dict(torch.load(\"classi/model_c\",map_location = self.device))\n",
        "    model2.to(device)\n",
        "    return model2\n",
        "  def Encode(self,i):\n",
        "    def encode(x):\n",
        "      l = []\n",
        "      chars = self.vocab_dict\n",
        "      for i in x:\n",
        "        l.append(chars[i])\n",
        "      return l\n",
        "    def Padding(x,PAD = 0,max_len = 512):\n",
        "      l = []\n",
        "      max_len = 512\n",
        "      for i in x:\n",
        "        a = i\n",
        "        if len(a) < max_len:\n",
        "          a = a + [PAD for i in range(max_len-len(a))]\n",
        "        l.append(a)\n",
        "      return np.array(l).reshape(len(x),max_len)\n",
        "\n",
        "    return  torch.tensor(Padding(list(map(encode,i)))).view(len(i),512).to(self.device)\n",
        "\n",
        "  def Decode(self,i):\n",
        "    def decode(k):\n",
        "      l = [j for j in k if j != 0 ]\n",
        "      seq = [chars[j] for j in l]\n",
        "      return \"\".join(seq)\n",
        "    H = list(map(decode,i))\n",
        "    G = []\n",
        "    for i in H:\n",
        "      if len(i)>512:\n",
        "        u = H.index(i)\n",
        "        for j in range(len(i)-512):\n",
        "          G.append(i[j:j+512])\n",
        "      else:\n",
        "        G.append(i)\n",
        "    return G,u\n",
        "  def Mean(self,i):\n",
        "    I = list(i.ravel())\n",
        "    sig = lambda x:np.e**(0*x)\n",
        "    Sum = [sig(np.abs(x-int(len(I)/2))) for x in range(len(I))]\n",
        "    wei = np.array([Sum[i]/sum(Sum) for i in range(len(I))]).reshape(len(I),1)\n",
        "    return np.sum(wei*i)\n",
        "\n",
        "  def enhancer(self,x):\n",
        "    wei = np.array([np.exp((i[0]-1)/(i[0])) for i in x])\n",
        "    return np.sum(np.array([i[0] for i in x])*wei)/np.sum(wei)\n",
        "\n",
        "  def predict_proba(self,i):\n",
        "    if len(i[0])>512:\n",
        "       l = [self.Encode([i[0][j:j+512]]) for j in range(len(i[0])-512)]\n",
        "       if len(l)>700:\n",
        "        L = [torch.concat(tuple(l[i*700:(i+1)*700])) for i in range(len(l)//700)] + [torch.concat(tuple(l[(len(l)//700)*700:(len(l)//700)*700+len(l)%700]))]\n",
        "        T = [self.classifier().predict_proba(i,\"sig\").tolist() for i in L ]\n",
        "        return self.enhancer(np.concatenate(tuple([i for i in T])))\n",
        "       else:\n",
        "         t = torch.concat(tuple(l))\n",
        "         return self.enhancer(self.classifier().predict_proba(t,\"sig\").tolist())\n",
        "    else:\n",
        "       seq = self.Encode(i)\n",
        "       U = np.array(self.classifier().predict_proba(seq,\"sig\").tolist())\n",
        "       out = np.array(U)\n",
        "       return out.reshape(len(i),1)\n",
        "\n",
        "model2 = Transformer(\"b\")\n",
        "model3 = Transformer(\"c\")\n",
        "\n",
        "\n",
        "import functools as FUNC\n",
        "from numba import njit\n",
        "class PPA():\n",
        "    def __init__(self, seq, model):\n",
        "        self.model = model\n",
        "        self.seq = seq\n",
        "        self.s = None\n",
        "        self.len = len(self.seq)\n",
        "        self.idx = None\n",
        "        self.p = None\n",
        "        self.dir = None\n",
        "        self.name = None\n",
        "\n",
        "    def attention_mask(self):\n",
        "        idx2 = self.Splicer(self.seq)[1]\n",
        "        k = self.T()\n",
        "        mask = []\n",
        "        for j in range(len(k)):\n",
        "           mask.append([True if len(k[0])>idx2[j]-i>-1 else False for i in range(len(k[j]))])\n",
        "        return mask\n",
        "\n",
        "    def Mean(self, mask, spliced):\n",
        "       u = []\n",
        "       for i in trange(len(spliced)):\n",
        "          o = self.model.predict_proba([spliced[i][j] for j in range(len(spliced[i])) if mask[i][j] == True])\n",
        "          u.append(np.mean(o))\n",
        "       return u\n",
        "\n",
        "    def SPLICE_scorer(self, i):\n",
        "        o = []\n",
        "        lmin = int(np.floor(len(i)/2))\n",
        "        lmax = int(np.ceil(len(i)/2))\n",
        "        for j in range(len(i) - lmin+1):\n",
        "            o.append(i[j:j + lmin])\n",
        "        return o\n",
        "\n",
        "    def Splicer(self, i):\n",
        "        o = []\n",
        "        Before = []\n",
        "        idx = self.idx\n",
        "        for j in range(len(i)):\n",
        "            n_b = j\n",
        "            n_a = len(i) - j - 1\n",
        "            if n_b <= int(np.floor(idx/2)):\n",
        "                before = i[j - min(int(np.floor(idx/2)), n_b):j]\n",
        "                after = i[j + 1:j + idx - len(before)]\n",
        "            elif n_a <= int(np.ceil(idx/2)):\n",
        "                before = i[j - idx + n_a+1:j]\n",
        "                after = i[j + 1:]\n",
        "            else:\n",
        "                before = i[j - min(int(np.floor(idx/2)), n_b):j]\n",
        "                after = i[j + 1:j + min(int(np.ceil(idx/2)), n_a)]\n",
        "            o.append(before + i[j] + after)\n",
        "            Before.append(len(before))\n",
        "        return o,Before\n",
        "\n",
        "    def T(self):\n",
        "        return list(map(self.SPLICE_scorer, self.Splicer(self.seq)[0]))\n",
        "\n",
        "    def Out(self):\n",
        "        def d(x):\n",
        "            if self.s>0.7:\n",
        "                return x*np.exp(-1.2*(x-self.s))\n",
        "            else:\n",
        "                if x > 0.7 :\n",
        "                    return x\n",
        "                else:\n",
        "                    #x * np.exp(-2 * np.abs(x - self.s))\n",
        "                    return x\n",
        "        return list(map(d,self.Mean(self.attention_mask(),self.T())))\n",
        "\n",
        "\n",
        "\n",
        "    def show(self,name:str):\n",
        "        import matplotlib.pyplot as plt\n",
        "        i = self.p\n",
        "        values = np.array(i).reshape(1, len(i))\n",
        "        y = range(len(i))\n",
        "        Y = [(j,1) for j in range(len(i)) if np.mean([i[j],i[min((j+1),len(i)-1)],i[max(0,(j-1))]])>0.6]\n",
        "        Y2 = [(j,1) for j in range(len(i)) if np.mean([i[j],i[min((j+1),len(i)-1)],i[min((j+2),len(i)-1)],i[min((j+3),len(i)-1)],i[min((j+4),len(i)-1)],i[min((j+5),len(i)-1)],i[max(0,(j-1))],i[max(0,(j-2))],i[max(0,(j-3))],i[max(0,(j-4))],i[max(0,(j-5))]])>0.85]\n",
        "        threshold = 0.5\n",
        "        above_threshold = np.maximum(values - threshold, 0)\n",
        "        below_threshold = np.minimum(values, threshold)\n",
        "        fig, (ax3 , ax4) = plt.subplots(2,1,sharex = True,sharey = True)\n",
        "        ax3.bar(y, below_threshold.ravel(), 0.9, color=\"lightblue\")\n",
        "        ax3.bar(y, above_threshold.ravel(), 0.9, color=\"lightgreen\",\n",
        "               bottom=below_threshold.ravel())\n",
        "        ax4.broken_barh(Y, (0.7, 0.03),\n",
        "               facecolors=( 'red'))\n",
        "        ax4.plot([0., y[-1]],[0.715,0.715],\"-b\")\n",
        "        for k in Y:\n",
        "            ax4.plot([k[0],k[0]+1],[0.715,0.715],\"-r\")\n",
        "\n",
        "        ax4.text(0,0.8 , \"LLPS-susceptible regions\",fontsize = 20)\n",
        "        ax3.plot([0., y[-1]], [threshold, threshold], \"k--\")\n",
        "        ax4.set_ylim([0,1])\n",
        "        ax3.set_ylim([0,1])\n",
        "\n",
        "        plt.subplots_adjust(\n",
        "                    wspace=0.4,\n",
        "                    hspace=0)\n",
        "        fig.set_figwidth(20)\n",
        "        fig.set_figheight(15)\n",
        "        plt.show()\n",
        "        if self.dir != None:\n",
        "          if self.name != None:\n",
        "            fig.savefig(self.dir+\"\\\\\"+self.name)\n",
        "          else:\n",
        "            name = np.random.randint(1000000)\n",
        "            fig.savefig(self.dir+\"\\\\\"+\"figure,sequenceID:\"+str(name)+\".png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ea1cf98ad940448a9f9415a6c022c433",
            "ff92f0a4968d415aad50a58b6e6d7686",
            "1f32c2cdf02a41b6926d292e62a899f7",
            "c5dc4066758640618e899348e71e56e9",
            "0df1feada4c645419b78d5fef1b296cd",
            "d32598ffa2b644d6a215ab313669b20d",
            "044620b9f02948ccb01b010107af655d",
            "5037ade164b74d7a8d29a9eb7a2c48a6",
            "f726fa5429ee4ed8a62e91741bf73957",
            "6d1b4b121b06400c8fb3e1a25baae9b1",
            "f189c6c2723547e3aeb3e000e2408b5e"
          ]
        },
        "id": "_R4AYlL7PfO2",
        "outputId": "abcbcc23-33b3-4cd3-c12b-9a87ec0379d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The request to the Slack API failed. (url: https://www.slack.com/api/chat.postMessage)\n",
            "The server responded with: {'ok': False, 'error': 'not_authed'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/96 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea1cf98ad940448a9f9415a6c022c433"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score : [[0.30924762]]\n"
          ]
        }
      ],
      "source": [
        "#@title Loading sequence , then hit `Runtime` -> `Run all`\n",
        "Sequence = \"YTSLNHSLIEEIQWQQEKNFQELLEKYKWKSLWRWWASEPNQSLPVNDPRSEQKPPKSESKGIVQQQNDLLDAIEAQQHLLQLTVWGIKQLQARVL\" #@param {type:\"string\"}\n",
        "name = None #@param {type:\"string\"}\n",
        "directory = None #@param {type:\"string\"}\n",
        "def enh(x):\n",
        "  wei = np.array([np.exp((i-1)/(i)) for i in x])\n",
        "  return np.sum(np.array(x)*wei)/np.sum(wei)\n",
        "\n",
        "def edit(i):\n",
        "  for j in i:\n",
        "    if j in \"\\t\\n \":\n",
        "      i = i.replace(j,\"\")\n",
        "  return i\n",
        "Sequence = edit(Sequence)\n",
        "\n",
        "u = model3.predict_proba([Sequence])\n",
        "\n",
        "c = PPA(Sequence,model3)\n",
        "c.s = np.mean(u)\n",
        "c.idx = 20\n",
        "#int(np.ceil(0.1*len(Sequence)))\n",
        "p = c.Out()\n",
        "c.p = p\n",
        "c.dir = directory\n",
        "c.name = name\n",
        "c.show(\"l\")\n",
        "print(\"Score : \"+str((2*u+2*enh(p))/4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VTZLFnEAdMO",
        "outputId": "40cdf9cf-4806-40af-8d2a-424f492026bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.756029666760937"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "model3.predict_proba([\"MATRIAILGAGPSGMAQLRAFQSAQEKGAEIPELVCFEKQADWGGQWNYTWRTGLDENGEPVHSSMYRYLWSNGPKECLEFADYTFDEHFGKPIASYPPREVLWDYIKGRVEKAGVRKYIRFNTAVRHVEFNEDSQTFTVTVQDHTTDTIYSEEFDYVVCCTGHFSTPYVPEFEGFEKFGGRILHAHDFRDALEFKDKTVLLVGSSYSAEDIGSQCYKYGAKKLISCYRTAPMGYKWPENWDERPNLVRVDTENAYFADGSSEKVDAIILCTGYIHHFPFLNDDLRLVTNNRLWPLNLYKGVVWEDNPKFFYIGMQDQWYSFNMFDAQAWYARDVIMGRLPLPSKEEMKADSMAWREKELTLVTAEEMYTYQGDYIQNLIDMTDYPSFDIPATNKTFLEWKHHKKENIMTFRDHSYRSLMTGTMAPKHHTPWIDALDDSLEAYLSDKSEIPVAKEAGSGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGGGAGHVPEYFVGIGTPISFYGHHHHHHHHHHHHHHHHHHHHHHHHGGAGHVPEYFVGIGTPISFYGENFKHLPEPFRIRVIEPVKRTTRAYREEAIIKSGMNPFLLDSEDVFIDLLTDSGTGAVTQSMQAAMMRGDEAYSGSRSYYALAESVKNIFGYQYTIPTHQGRGAEQIYIPVLIKKREQEKGLDRSKMVAFSNYFFDTTQGHSQINGCTVRNVYIKEAFDTGVRYDFKGNFDLEGLERGIEEVGPNNVPYIVATITSNSAGGQPVSLANLKAMYSIAKKYDIPVVMDSARFAENAYFIKQREAEYKDWTIEQITRETYKYADMLAMSAKKDAMVPMGGLLCMKDDSFFDVYTECRTLCVVQEGFPTYGGLEGGAMERLAVGLYDGMNLDWLAYRIAQVQYLVDGLEEIGVVCQQAGGHAAFVDAGKLLPHIPADQFPAQALACELYKVAGIRAVEIGSFLLGRDPKTGKQLPCPAELLRLTIPRATYTQTHMDFIIEAFKHVKENAANIKGLTFTYEPKVLRHFTAKLKEV\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enh(p),np.mean(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EruwB9NC0HRZ",
        "outputId": "cc7e35e5-a020-46b1-f970-b475ca35db06"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5606659435139937, 0.28297123235360083)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gz1c7-vxEzfn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "cb24cb48-ab9e-4007-a71d-e7368858a7f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'PPA' object has no attribute 'split'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-be2fa397499a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFiltered_train\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mFiltered_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mFiltered_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFiltered_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFiltered_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PPA' object has no attribute 'split'"
          ]
        }
      ],
      "source": [
        "Filtered_train  = [i for i in k.split(\"#\") ][1:]\n",
        "Filtered_val = [i for i in l.split(\"#\") ][1:]\n",
        "Filtered_neg = [i for i in c.split(\"\\n\")]\n",
        "pos = Filtered_train + Filtered_val"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pos)"
      ],
      "metadata": {
        "id": "JYUNxTeTjhzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = [model3.predict_proba([i]) for i in tqdm(pos)]"
      ],
      "metadata": {
        "id": "zGBuPkyoj4ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"AA.txt\",\"w\") as d:\n",
        "  for i in S:\n",
        "    d.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "CVAgzPakn8HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg = [model3.predict_proba([i]) for i in tqdm(Filtered_neg)]\n",
        "with open(\"AAA.txt\",\"w\") as d:\n",
        "  for i in neg:\n",
        "    d.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "UFiUdFgekXv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"negative_dataset (2).txt\") as x:\n",
        "  c = x.read()"
      ],
      "metadata": {
        "id": "FMFUlc3iHZoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Filtered_neg = [i for i in c.split(\"\\n\")]\n"
      ],
      "metadata": {
        "id": "1oC7FK_LIC-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Filtered_neg)"
      ],
      "metadata": {
        "id": "fc1BgCHMIHan"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOKu4t8AD8s+tOL/XyEl+px",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea1cf98ad940448a9f9415a6c022c433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff92f0a4968d415aad50a58b6e6d7686",
              "IPY_MODEL_1f32c2cdf02a41b6926d292e62a899f7",
              "IPY_MODEL_c5dc4066758640618e899348e71e56e9"
            ],
            "layout": "IPY_MODEL_0df1feada4c645419b78d5fef1b296cd"
          }
        },
        "ff92f0a4968d415aad50a58b6e6d7686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32598ffa2b644d6a215ab313669b20d",
            "placeholder": "​",
            "style": "IPY_MODEL_044620b9f02948ccb01b010107af655d",
            "value": "100%"
          }
        },
        "1f32c2cdf02a41b6926d292e62a899f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5037ade164b74d7a8d29a9eb7a2c48a6",
            "max": 96,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f726fa5429ee4ed8a62e91741bf73957",
            "value": 96
          }
        },
        "c5dc4066758640618e899348e71e56e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1b4b121b06400c8fb3e1a25baae9b1",
            "placeholder": "​",
            "style": "IPY_MODEL_f189c6c2723547e3aeb3e000e2408b5e",
            "value": " 96/96 [00:11&lt;00:00,  8.61it/s]"
          }
        },
        "0df1feada4c645419b78d5fef1b296cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32598ffa2b644d6a215ab313669b20d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044620b9f02948ccb01b010107af655d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5037ade164b74d7a8d29a9eb7a2c48a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f726fa5429ee4ed8a62e91741bf73957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d1b4b121b06400c8fb3e1a25baae9b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f189c6c2723547e3aeb3e000e2408b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}